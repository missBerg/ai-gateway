# Copyright Envoy AI Gateway Authors
# SPDX-License-Identifier: Apache-2.0
# The full text of the Apache license is available in the LICENSE file at
# the root of the repo.


services:
  # ollama-pull pulls the models defined in .env.ollama, to avoid 404s.
  ollama-pull:
    image: alpine/ollama
    container_name: ollama-pull
    environment:
      OLLAMA_HOST: localhost:11434  # intentionally not 127.0.0.1
    env_file:
      - ../../.env.ollama
    entrypoint: sh
    command: -c 'env | grep _MODEL | cut -d= -f2 | xargs -I{} ollama pull {}'
    extra_hosts:  # send localhost traffic to the docker host, e.g. your laptop
      - "localhost:host-gateway"

  # aigw is the Envoy AI Gateway CLI a.k.a standalone mode.
  aigw:
    image: envoyproxy/ai-gateway-cli:latest
    # Note: Run `make build.aigw GOOS_LIST=linux` from the project root prior
    # to `docker compose up --build --wait -d` here.
    build:
      context: ../..
      dockerfile: Dockerfile
      args:
        VARIANT: base-nossl
        COMMAND_NAME: aigw
    container_name: aigw
    depends_on:
      ollama-pull:
        condition: service_completed_successfully
    environment:
      - OPENAI_HOST=host.docker.internal
    ports:
      - "1975:1975"  # OpenAI compatible endpoint at /v1
      - "1064:1064"  # Prometheus endpoint at /metrics
    extra_hosts:  # localhost:host-gateway trick doesn't work with aigw
      - "host.docker.internal:host-gateway"
    volumes:
      - ./ai-gateway-local.yaml:/config.yaml:ro
    command: ["run", "/config.yaml"]

  # chat-completion is a simple curl-based test client for sending requests to aigw.
  chat-completion:
    image: golang:1.25
    container_name: chat-completion
    profiles: ["test"]
    env_file:
      - ../../.env.ollama
    depends_on:
      aigw:
        condition: service_started
    command:
      - sh
      - -c
      - |
        curl -s -w %{http_code} \
          -X POST http://aigw:1975/v1/chat/completions \
          -H "Authorization: Bearer unused" \
          -H "Content-Type: application/json" \
          -d "{\"model\":\"$$CHAT_MODEL\",\"messages\":[{\"role\":\"user\",\"content\":\"Answer in up to 3 words: Which ocean contains Bouvet Island?\"}]}"
