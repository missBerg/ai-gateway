---
id: upstream-auth
title: Upstream Authentication
sidebar_position: 8
---
# Upstream Authentication

## Overview

Upstream Authentication secures the connectivity between the Gateway and the LLM Providers. This layer ensures secure communication and proper access control when the Gateway interacts with various AI service providers like AWS Bedrock, Azure OpenAI, Open AI, Mistral, Gemini, and other platforms.

## Why Upstream Authentication Matters

Upstream Authentication is essential for several reasons:

1. **Security Layer**: It provides a secure authentication mechanism between the Gateway and upstream providers, preventing credentials sprawl across teams and organizations.

1. **Credential Management**: It allows AI platform teams to handle the secure storage and management of credentials and use them in one place. This makes the revocation and rotation of credentials easier.

1. **Compliance**: It helps organizations meet security and compliance requirements by maintaining proper authentication protocols and enforcing controlled usage of AI resources.

## Enterprise Security Architecture

In enterprise environments, security is implemented in multiple layers:

1. **Client to Gateway Authentication**
   - Clients must authenticate to the Gateway using appropriate methods (API keys, OAuth, etc.) aligned with the organization's security standards.
   - This ensures only authorized clients can access the Gateway's services, and the Gateway enforces the access to the upstream providers and models.

    :::tip
    Check out [Envoy Gateway Security Documentation](https://gateway.envoyproxy.io/docs/tasks/security/) for Client to Gateway security configuration options.
    :::

2. **Gateway to Upstream Authentication**
   - The Gateway must authenticate to upstream providers.
   - This layer is managed by Upstream Authentication.
   - Ensures secure communication between the Gateway and AI service providers.

<div style={{ textAlign: 'center' }}>
  ![Upstream Authentication](/diagrams/upstream-auth.png)
</div>

## Credential Management

**Where the providers support short lived access credentials**, the Envoy AI Gateway control plane supports automated credential management with the providers' identity system. This ensures a short-lived proof of authorization, such as an access token, is used when the request is sent to the upstream service.

**For providers that support long lived access credentials**, the Envoy AI Gateway control plane supports a manual credential management process. In these cases the credentials, like API keys, are stored in Kubernetes secrets and managed by the administrator.

### Automated Credential Management

The Gateway integrates with each provider's identity system to ensure secure, short-lived authentication:

- **AWS Bedrock**: Uses OIDC integration with AWS STS to generate temporary credentials for each request
- **Azure OpenAI**: Leverages Entra ID (formerly Azure AD) to provide short-lived access tokens
- **GCP VertexAI**: Uses GCP workload federation with Google STS to generate temporary credentials for each request


In both cases, the Gateway automatically manages these credentials, ensuring that each request to upstream providers is sent with short-lived credentials. This approach significantly reduces the risk of credential exposure and aligns with enterprise security best practices.

:::info
Learn more about connecting to [AWS Bedrock](/docs/getting-started/connect-providers/aws-bedrock) and [Azure OpenAI](/docs/getting-started/connect-providers/azure-openai) in the provider specific documentation.
:::

### Manual Credential Management

For providers that support long lived access credentials, the Envoy AI Gateway control plane supports a manual credential management process. In these cases the credentials, like API keys, are stored in Kubernetes secrets and managed by the AI Gateway administrator. Envoy AI Gateway will use the credentials from the secret to authenticate with the upstream service, attaching them to each request by securely retrieving them from the secret and attaching them to the request.

:::info
Learn more about connecting to [OpenAI](/docs/getting-started/connect-providers/openai) and adding your API key to the secret. You can use the same approach for other providers that support long lived credentials.
:::

## Environment Variable Security

For additional security when configuring the AI Gateway, you can reference secrets stored in Kubernetes for sensitive environment variables instead of storing them as plain text values.

### Using secretKeyRef for Environment Variables

When configuring the AI Gateway's external processor (ExtProc) with environment variables that contain sensitive data, you can use `secretKeyRef` to reference values from Kubernetes secrets:

```yaml
extProc:
  extraEnvVars:
    - name: OTEL_EXPORTER_OTLP_HEADERS
      valueFrom:
        secretKeyRef:
          name: otel-headers-secret
          key: authorization-header
    - name: CUSTOM_API_KEY
      valueFrom:
        secretKeyRef:
          name: api-credentials
          key: custom-key
```

### Creating the Required Secrets

First, create the Kubernetes secrets containing your sensitive values:

```bash
# Create secret for OTEL headers
kubectl create secret generic otel-headers-secret \
  --from-literal=authorization-header="Bearer your-token-here" \
  -n envoy-ai-gateway-system

# Create secret for API credentials
kubectl create secret generic api-credentials \
  --from-literal=custom-key="your-api-key-here" \
  -n envoy-ai-gateway-system
```

### Alternative: Inline secretKeyRef Syntax

For convenience, the AI Gateway also supports an inline `secretKeyRef` syntax when using the `extraEnvVars` string format:

```bash
helm upgrade ai-eg oci://docker.io/envoyproxy/ai-gateway-helm \
  --version v0.0.0-latest \
  --namespace envoy-ai-gateway-system \
  --set 'extProc.extraEnvVars=OTEL_EXPORTER_OTLP_HEADERS=secretKeyRef {"name":"otel-headers-secret","key":"authorization-header"}'
```

This inline format supports various JSON formatting styles:
- `secretKeyRef {"name":"SECRET_NAME","key":"KEY"}`
- `secretKeyRef{"name":"SECRET_NAME","key":"KEY"}`
- `secretKeyRef { "name": "SECRET_NAME", "key": "KEY" }`

### Mixed Environment Variables

You can combine regular environment variables with secret references:

```bash
helm upgrade ai-eg oci://docker.io/envoyproxy/ai-gateway-helm \
  --version v0.0.0-latest \
  --namespace envoy-ai-gateway-system \
  --set 'extProc.extraEnvVars=OTEL_SERVICE_NAME=ai-gateway;OTEL_EXPORTER_OTLP_HEADERS=secretKeyRef {"name":"otel-secret","key":"headers"}'
```

### Security Best Practices

1. **Use secrets for sensitive data**: Always store API keys, tokens, and other credentials in Kubernetes secrets rather than as plain text values.

2. **Apply principle of least privilege**: Ensure the AI Gateway service account has only the minimum permissions needed to read the required secrets.

3. **Rotate credentials regularly**: Implement a rotation strategy for your secrets and update the Kubernetes secrets accordingly.

4. **Monitor secret access**: Use Kubernetes audit logs to monitor access to sensitive secrets.

## Conclusion

Upstream Authentication is a key component of the Envoy AI Gateway's security architecture. It ensures secure communication between the Gateway and upstream AI service providers while supporting modern authentication methods and enterprise security requirements. Combined with proper secret management for environment variables, you can maintain a secure and compliant AI infrastructure in your enterprise environments.
